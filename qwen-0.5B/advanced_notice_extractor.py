import torch
from transformers import AutoTokenizer, AutoModelForCausalLM
import json
import re
import sys

class FixedExtractor:
    def __init__(self, model_path: str):
        """åˆå§‹åŒ–æ¨¡å‹"""
        print("ğŸ”§ åŠ è½½æ¨¡å‹ä¸­...")
        self.tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)
        self.model = AutoModelForCausalLM.from_pretrained(
            model_path,
            torch_dtype=torch.float32,
            device_map="cpu",
            trust_remote_code=True
        ).eval()
        
        if self.tokenizer.pad_token is None:
            self.tokenizer.pad_token = self.tokenizer.eos_token
        
        print("âœ… æ¨¡å‹åŠ è½½å®Œæˆ")
    
    def extract(self, notice_text: str) -> dict:
        """æå–ä¿¡æ¯"""
        # ä¼˜åŒ–promptï¼Œæ˜ç¡®è¦æ±‚ä¸­æ–‡å­—æ®µ
        prompt = f"""é€šçŸ¥ï¼š{notice_text}
è¯·æå–ï¼šä»»åŠ¡ã€æ—¶é—´ã€åœ°ç‚¹ã€ç´§æ€¥ç¨‹åº¦
æ³¨æ„ï¼šè¯·ä½¿ç”¨ä¸­æ–‡é”®åï¼ˆä»»åŠ¡ã€æ—¶é—´ã€åœ°ç‚¹ã€ç´§æ€¥ç¨‹åº¦ï¼‰
JSONæ ¼å¼è¾“å‡ºï¼š"""
        
        print(f"\nğŸ“‹ è¾“å…¥é€šçŸ¥: {notice_text}")
        print(f"ğŸ“ Prompt: {prompt}")
        
        # ç¼–ç 
        inputs = self.tokenizer(
            prompt,
            return_tensors="pt",
            max_length=150,
            truncation=True
        )
        
        print(f"âœ… è¾“å…¥é•¿åº¦: {inputs['input_ids'].shape[1]}")
        
        # ç”Ÿæˆ
        with torch.no_grad():
            outputs = self.model.generate(
                input_ids=inputs['input_ids'],
                attention_mask=inputs['attention_mask'],
                max_new_tokens=100,
                do_sample=False,
                temperature=0.1,
                pad_token_id=self.tokenizer.pad_token_id,
                eos_token_id=self.tokenizer.eos_token_id
            )
        
        # è§£ç 
        full_response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
        generated_text = full_response[len(prompt):].strip()
        
        print(f"ğŸ¤– æ¨¡å‹è¾“å‡º:\n{generated_text}")
        print("-" * 50)
        
        # è§£æç»“æœ
        return self.smart_parse(generated_text, notice_text)
    
    def smart_parse(self, model_output: str, original_notice: str) -> dict:
        """æ™ºèƒ½è§£æ"""
        # å°è¯•æå–JSON
        json_data = self.extract_json(model_output)
        
        if json_data:
            print("âœ… æ‰¾åˆ°JSONæ•°æ®")
            result = self.process_json_with_fallback(json_data, original_notice)
            result["è§£ææ–¹å¼"] = "JSONè§£æ"
        else:
            print("âš ï¸  æœªæ‰¾åˆ°æ ‡å‡†JSONï¼Œä»æ–‡æœ¬ä¸­æå–")
            result = self.extract_from_text(original_notice)
            result["è§£ææ–¹å¼"] = "æ–‡æœ¬è§£æ"
        
        return result
    
    def extract_json(self, text: str):
        """æå–JSON"""
        text = text.strip()
        
        # æŸ¥æ‰¾JSON
        start = text.find('{')
        end = text.rfind('}')
        
        if start != -1 and end != -1:
            json_str = text[start:end+1]
            
            try:
                # æ¸…ç†
                json_str = self.clean_json(json_str)
                return json.loads(json_str)
            except json.JSONDecodeError:
                # å°è¯•ä¿®å¤
                try:
                    json_str = self.fix_json(json_str)
                    return json.loads(json_str)
                except:
                    return None
        
        return None
    
    def clean_json(self, json_str: str) -> str:
        """æ¸…ç†JSONå­—ç¬¦ä¸²"""
        # ç§»é™¤ä»£ç å—æ ‡è®°
        json_str = json_str.replace('```json', '').replace('```', '')
        
        # å•å¼•å·è½¬åŒå¼•å·
        json_str = json_str.replace("'", '"')
        
        return json_str.strip()
    
    def fix_json(self, json_str: str) -> str:
        """ä¿®å¤JSON"""
        # ä¿®å¤é”®åç¼ºå°‘å¼•å·
        json_str = re.sub(r'(\s*)([a-zA-Z\u4e00-\u9fa5_]+)(\s*):', r'\1"\2"\3:', json_str)
        
        # ä¿®å¤æœ«å°¾é€—å·
        json_str = re.sub(r',(\s*[}\]])', r'\1', json_str)
        
        # ä¿®å¤Pythonçš„None
        json_str = json_str.replace("None", "null")
        
        return json_str
    
    def process_json_with_fallback(self, data: dict, original_notice: str) -> dict:
        """å¤„ç†JSONæ•°æ®ï¼Œå¦‚æœå¤±è´¥åˆ™ä½¿ç”¨å¤‡ç”¨æ–¹æ³•"""
        result = {
            "ä»»åŠ¡": [],
            "æ—¶é—´": [],
            "åœ°ç‚¹": [],
            "ç´§æ€¥ç¨‹åº¦": "æ™®é€š"
        }
        
        # å°è¯•è§£æJSON
        try:
            # å¤„ç†æ‰€æœ‰å¯èƒ½çš„å­—æ®µå
            processed = False
            
            # æ£€æŸ¥ä»»åŠ¡å­—æ®µ
            task_fields = ["ä»»åŠ¡", "task", "Task", "tasks", "Tasks"]
            for field in task_fields:
                if field in data and data[field]:
                    value = data[field]
                    if isinstance(value, list):
                        result["ä»»åŠ¡"] = [str(v).strip() for v in value if v]
                    else:
                        result["ä»»åŠ¡"] = [str(value).strip()]
                    processed = True
                    break
            
            # æ£€æŸ¥æ—¶é—´å­—æ®µ
            time_fields = ["æ—¶é—´", "time", "Time", "times", "Times", "æ—¥æœŸ", "date"]
            for field in time_fields:
                if field in data and data[field]:
                    value = data[field]
                    if isinstance(value, list):
                        result["æ—¶é—´"] = [str(v).strip() for v in value if v]
                    else:
                        result["æ—¶é—´"] = [str(value).strip()]
                    processed = True
                    break
            
            # æ£€æŸ¥åœ°ç‚¹å­—æ®µ
            location_fields = ["åœ°ç‚¹", "location", "Location", "locations", "Locations", "place"]
            for field in location_fields:
                if field in data and data[field]:
                    value = data[field]
                    if isinstance(value, list):
                        result["åœ°ç‚¹"] = [str(v).strip() for v in value if v]
                    else:
                        result["åœ°ç‚¹"] = [str(value).strip()]
                    processed = True
                    break
            
            # æ£€æŸ¥ç´§æ€¥ç¨‹åº¦å­—æ®µ
            urgency_fields = ["ç´§æ€¥ç¨‹åº¦", "urgency", "Urgency", "ç´§æ€¥", "importance"]
            for field in urgency_fields:
                if field in data and data[field]:
                    value = str(data[field]).strip()
                    # å¤„ç†è‹±æ–‡
                    if value.lower() in ["urgent", "ç´§æ€¥"]:
                        result["ç´§æ€¥ç¨‹åº¦"] = "ç´§æ€¥"
                    elif value.lower() in ["important", "é‡è¦"]:
                        result["ç´§æ€¥ç¨‹åº¦"] = "é‡è¦"
                    elif value.lower() in ["normal", "æ™®é€š"]:
                        result["ç´§æ€¥ç¨‹åº¦"] = "æ™®é€š"
                    elif value in ["ç´§æ€¥", "é‡è¦", "æ™®é€š"]:
                        result["ç´§æ€¥ç¨‹åº¦"] = value
                    processed = True
                    break
            
            # å¦‚æœJSONè§£ææˆåŠŸï¼Œè¿”å›ç»“æœ
            if processed and result["ä»»åŠ¡"]:
                return result
        
        except Exception as e:
            print(f"âš ï¸  JSONè§£æå‡ºé”™: {e}")
        
        # å¦‚æœJSONè§£æå¤±è´¥æˆ–ç»“æœä¸å®Œæ•´ï¼Œä½¿ç”¨æ–‡æœ¬æå–
        print("âš ï¸  JSONè§£æä¸å®Œæ•´ï¼Œä½¿ç”¨æ–‡æœ¬æå–è¡¥å……")
        text_result = self.extract_from_text(original_notice)
        
        # åˆå¹¶ç»“æœï¼šä¼˜å…ˆä½¿ç”¨JSONçš„ç»“æœï¼Œç¼ºå¤±çš„ç”¨æ–‡æœ¬ç»“æœè¡¥å……
        if not result["ä»»åŠ¡"] and text_result["ä»»åŠ¡"]:
            result["ä»»åŠ¡"] = text_result["ä»»åŠ¡"]
        
        if not result["æ—¶é—´"] and text_result["æ—¶é—´"]:
            result["æ—¶é—´"] = text_result["æ—¶é—´"]
        
        if not result["åœ°ç‚¹"] and text_result["åœ°ç‚¹"]:
            result["åœ°ç‚¹"] = text_result["åœ°ç‚¹"]
        
        if result["ç´§æ€¥ç¨‹åº¦"] == "æ™®é€š" and text_result["ç´§æ€¥ç¨‹åº¦"] != "æ™®é€š":
            result["ç´§æ€¥ç¨‹åº¦"] = text_result["ç´§æ€¥ç¨‹åº¦"]
        
        return result
    
    def extract_from_text(self, notice: str) -> dict:
        """ä»æ–‡æœ¬ä¸­æå–"""
        result = {
            "ä»»åŠ¡": [],
            "æ—¶é—´": [],
            "åœ°ç‚¹": [],
            "ç´§æ€¥ç¨‹åº¦": "æ™®é€š"
        }
        
        # æå–ä»»åŠ¡
        if "æäº¤" in notice:
            if "ä½œä¸š" in notice:
                result["ä»»åŠ¡"] = ["æäº¤ä½œä¸š"]
            elif "æŠ¥å‘Š" in notice:
                result["ä»»åŠ¡"] = ["æäº¤æŠ¥å‘Š"]
            else:
                result["ä»»åŠ¡"] = ["æäº¤æ–‡ä»¶"]
        elif "å‚åŠ " in notice or "ä¼šè®®" in notice:
            result["ä»»åŠ¡"] = ["å‚åŠ ä¼šè®®"]
        elif "è€ƒè¯•" in notice:
            result["ä»»åŠ¡"] = ["å‚åŠ è€ƒè¯•"]
        elif "é›†åˆ" in notice:
            result["ä»»åŠ¡"] = ["é›†åˆ"]
        
        # æå–æ—¶é—´
        time_patterns = [
            r'(\d{1,2}æœˆ\d{1,2}æ—¥[ä¸Šä¸‹]åˆ\d{1,2}:\d{2})',
            r'(\d{1,2}æœˆ\d{1,2}æ—¥)',
            r'(\d{1,2}æœˆ\d{1,2}æ—¥å‰)',
            r'(å‘¨[ä¸€äºŒä¸‰å››äº”å…­æ—¥][ä¸Šä¸‹]åˆ\d{1,2}ç‚¹)',
            r'(æ˜å¤©[ä¸Šä¸‹]åˆ\d{1,2}ç‚¹)',
            r'(ä»Šå¤©[ä¸Šä¸‹]åˆ\d{1,2}ç‚¹)',
            r'(\d{1,2}:\d{2})'
        ]
        
        for pattern in time_patterns:
            match = re.search(pattern, notice)
            if match:
                result["æ—¶é—´"] = [match.group(1)]
                break
        
        # æå–åœ°ç‚¹
        # é‚®ç®±
        email_match = re.search(r'([\w\.-]+@[\w\.-]+\.\w+)', notice)
        if email_match:
            result["åœ°ç‚¹"] = [email_match.group(1)]
        # ç³»ç»Ÿ/å¹³å°
        elif "ç³»ç»Ÿ" in notice:
            result["åœ°ç‚¹"] = ["å­¦ä¹ ç³»ç»Ÿ"]
        # æ•™å®¤
        elif "æ•™å®¤" in notice:
            room_match = re.search(r'(\w+æ•™å®¤)', notice)
            if room_match:
                result["åœ°ç‚¹"] = [room_match.group(1)]
        # ä¼šè®®å®¤
        elif "ä¼šè®®å®¤" in notice:
            result["åœ°ç‚¹"] = ["ä¼šè®®å®¤"]
        
        # ç´§æ€¥ç¨‹åº¦
        if "ç´§æ€¥" in notice:
            result["ç´§æ€¥ç¨‹åº¦"] = "ç´§æ€¥"
        elif "åŠ¡å¿…" in notice or "å¿…é¡»" in notice or "é€¾æœŸä¸å€™" in notice:
            result["ç´§æ€¥ç¨‹åº¦"] = "é‡è¦"
        elif "å‡†æ—¶" in notice or "æŒ‰æ—¶" in notice:
            result["ç´§æ€¥ç¨‹åº¦"] = "é‡è¦"
        
        return result
    
    def print_result(self, result: dict, notice: str = ""):
        """æ‰“å°ç»“æœ"""
        print("\n" + "="*60)
        print("âœ… æå–ç»“æœ:")
        print("="*60)
        
        if notice:
            print(f"ğŸ“„ åŸå§‹é€šçŸ¥: {notice}")
            print("-" * 60)
        
        task_count = len(result["ä»»åŠ¡"])
        
        if task_count == 0:
            print("ğŸ“­ æœªå‘ç°æ˜ç¡®ä»»åŠ¡")
        else:
            print(f"ğŸ“‹ å‘ç° {task_count} ä¸ªä»»åŠ¡:")
            
            for i in range(task_count):
                print(f"\nä»»åŠ¡ {i+1}:")
                print(f"  ğŸ“ä»»åŠ¡ {result['ä»»åŠ¡'][i]}")
                
                time = result['æ—¶é—´'][i] if i < len(result['æ—¶é—´']) else 'æœªæåŠ'
                print(f"  â°æ—¶é—´ {time}")
                
                location = result['åœ°ç‚¹'][i] if i < len(result['åœ°ç‚¹']) else 'æœªæåŠ'
                print(f"  ğŸ“åœ°ç‚¹ {location}")
        
        urgency_emoji = {"ç´§æ€¥": "ğŸš¨", "é‡è¦": "âš ï¸", "æ™®é€š": "ğŸ“Œ"}.get(result["ç´§æ€¥ç¨‹åº¦"], "ğŸ“Œ")
        print(f"\nğŸš¨ ç´§æ€¥ç¨‹åº¦: {urgency_emoji} {result['ç´§æ€¥ç¨‹åº¦']}")
        
        if "è§£ææ–¹å¼" in result:
            print(f"ğŸ”§ è§£ææ–¹å¼: {result['è§£ææ–¹å¼']}")
        
        print("="*60)

def quick_test():
    """å¿«é€Ÿæµ‹è¯•"""
    MODEL_PATH = r"G:\qwen-agent\models\Qwen2-0.5B-Instruct"
    
    print("="*70)
    print("ğŸ¤– ä¿®å¤ç‰ˆé€šçŸ¥ä¿¡æ¯æå–æµ‹è¯•")
    print("="*70)
    
    extractor = FixedExtractor(MODEL_PATH)
    
    # æµ‹è¯•æœ‰é—®é¢˜çš„æ¡ˆä¾‹
    test_cases = [
        ("ä½œä¸šæäº¤é—®é¢˜", "æ•°æ®ç»“æ„ä½œä¸šï¼Œ12æœˆ31æ—¥å‰æäº¤åˆ°å­¦ä¹ é€šç³»ç»Ÿï¼Œé€¾æœŸä¸å€™ã€‚"),
        ("è€ƒè¯•é€šçŸ¥", "é«˜ç­‰æ•°å­¦è€ƒè¯•ï¼š12æœˆ25æ—¥9:00-11:00ï¼Œ302æ•™å®¤ã€‚"),
        ("å¤šä»»åŠ¡è‹±æ–‡å­—æ®µ", "è¯·æäº¤æŠ¥å‘Šåˆ°é‚®ç®±report@test.comï¼Œå¹¶å‚åŠ å‘¨ä¸€ä¼šè®®ã€‚"),
        ("ç´§æ€¥ä¼šè®®", "ç´§æ€¥ï¼ä»Šå¤©ä¸‹åˆ3ç‚¹ï¼Œ301ä¼šè®®å®¤å¼€ä¼šã€‚")
    ]
    
    for name, text in test_cases:
        print(f"\n{'='*70}")
        print(f"ğŸ§ª æµ‹è¯•: {name}")
        print(f"ğŸ“ å†…å®¹: {text}")
        print('-'*70)
        
        result = extractor.extract(text)
        extractor.print_result(result, text)
        
        # ä¿å­˜
        import time
        filename = f"{name}_ä¿®å¤æµ‹è¯•_{int(time.time())}.json"
        with open(filename, "w", encoding="utf-8") as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ ä¿å­˜åˆ°: {filename}")
        
        if name != test_cases[-1][0]:
            input("\nâ æŒ‰Enterç»§ç»­...")

if __name__ == "__main__":
    try:
        quick_test()
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
    finally:
        input("\nâ æŒ‰Enteré€€å‡º...")